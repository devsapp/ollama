edition: 3.0.0
name:  
access: {{ access }}
vars:
  region: {{ region }}
  name: {{ name }}
  role: {{ roleArn }}
  gpuInstanceType: {{ gpuInstanceType }}
  gpuMemorySize: {{ gpuMemorySize }}
  memorySize: {{ memorySize }}
  cpu: {{ cpu }}
  modelName: "{{ if type === '通义千问 0.5B' }}qwen:0.5b{{ else if type === '通义千问 7B'}}qwen:7b{{else if type === 'llama3 8B'}}llama3:8b{{ else }}qwen:7b{{/if}}"
  image: "registry.${vars.region}.aliyuncs.com/aliyun-fc/ollama:{{ if type === '通义千问 0.5B' }}qwen-0.5b-v1{{ else if type === '通义千问 7B'}}qwen-7b-v1{{else if type === 'llama3 8B'}}llama3-8b-v1{{ else }}multi-v1{{/if}}"

resources:
  ollama:
    component: fc3
    props:
      region: ${vars.region}
      handler: index.handler
      functionName: ${vars.name}
      role: ${vars.role}
      description: ''
      timeout: 60
      diskSize: 10240
      internetAccess: true
      instanceLifecycleConfig:
        initializer:
          handler: 'true'
          timeout: 300
      gpuConfig:
        gpuMemorySize: ${vars.gpuMemorySize}
        gpuType: ${vars.gpuInstanceType}
      runtime: custom-container
      cpu: ${vars.cpu}
      customContainerConfig:
        image: "${vars.image}"
        port: 8000
      instanceConcurrency: 1
      memorySize: ${vars.memorySize}
      environmentVariables:
        MODEL: ${vars.modelName}
      triggers:
        - triggerConfig:
            methods:
              - GET
              - POST
            authType: anonymous
            disableURLInternet: false
          triggerName: defaultTrigger
          description: ''
          qualifier: LATEST
          triggerType: http
